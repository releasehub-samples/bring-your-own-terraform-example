---
app: terraform-s3-backend        # Update to match the name selected when creating your application
context: YOUR_EKS_CLUSTER        # Update this field to match one of your Release-managed EKS clusters
domain: YOUR_RELEASE_SUBDOMAIN   # Update to a domain or subdomain that you want to use as the root node for any DNS ingress endpoints you later define.
auto_deploy: true
repo_name: releasehub-samples/release-with-terraform   # Change this to match your forked repository
tracking_branch: ecs    # TODO: change back to main once merged

# Builds are where you are can optionally tell us to buily your Dockerfile(s)
# and push the image artifact to AWS ECR or Google GCR. The name that you give
# the service will later be part of the string you can use to reference the
# build when defining a service. You can also reference any existing image
# in your private ECR, GCR, Artifactory, or DockerHub repo, or public images
# in the same.
builds:
# When we do an image build for you, you can reference the image via the following
# string in our services: "{source_org_name}/{source_repo_name}/{build_name}"
# in other words: "releasehub-samples/release-with-terraform/terraform"
- name: terraform                     # any name you want
  context: examples/aws-s3-backend/ecs-fargate    # context = folder
  dockerfile: Dockerfile

# "services" are those where you define which container images you want
# to run as either a long-lived service (e.g. NodeJS frontend) or as 
# a one-time job.
services:
- name: terraform
  image: releasehub-samples/release-with-terraform/terraform
  has_repo: true

# Allows you to specify overrides for other properties in this template
# based on your environment type (not used in this demo):
environment_templates:
- name: ephemeral
- name: permanent

# These are defaults for K8s containers that we spin up for you and only apply
# if you use our "services" abstraction. You can override these with the templates
# above and/or on a per-service basis:
resources:
  cpu:
    limits: 1000m
    requests: 100m
  memory:
    limits: 1Gi
    requests: 100Mi
  replicas: 1

# Release jobs can derive their image from either a Release service with "from_services", 
# or can reference an image directly. In our case, we'll re-use our service definition
# above:
jobs:
- name: terraform-apply
  from_services: terraform 
  command:                   
  - "./bin/apply.sh"   
  completed_timeout: 600       

- name: terraform-destroy
  from_services: terraform
  command:
  - "./bin/destroy.sh"
  completed_timeout: 600


# Above, we define our environment components. 
# We use the workflows below to tell Release when
# to create our services or tear them down.
workflows:

# Runs when environment first created
- name: setup       
  parallelize:
  - step: deploy
    tasks:
    - services.terraform        # this runs an identical container to that used by the job below, with the only difference being this service's Dockerfile entrypoint is a sleep command that keeps it running. This is handy for opening a remote session to test or debug manually from within the context of your environment's namespace.
    - jobs.terraform-apply 

# Runs when commit is pushed to a repo, or if you disable auto-update
# on commit, when you trigger an update via UI & CLI
- name: patch
  parallelize:
  - step: patch
    tasks:
    - services.all            
    - jobs.terraform-apply

- name: teardown
  order_from:
  - jobs.terraform-destroy      
  - release.remove_environment
